{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "647aeabe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Bidirectional, LSTM\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "sns.set(style='darkgrid', palette='muted', font_scale=1.5, rc={'figure.figsize':(20,10)})\n",
    "\n",
    "RANDOM_SEED = 40\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29acd333",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a56094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, columns, start=None, stop=None):\n",
    "    df = pd.read_pickle(path)\n",
    "    return df.loc[start:stop, columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8998e1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data('../../data/ica_summary.pkl', columns=['artiklar'], stop='2021-03-28')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7429ab08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artiklar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-03-24</th>\n",
       "      <td>1949.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-25</th>\n",
       "      <td>3807.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-26</th>\n",
       "      <td>4856.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-27</th>\n",
       "      <td>884.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-28</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            artiklar\n",
       "2021-03-24    1949.0\n",
       "2021-03-25    3807.0\n",
       "2021-03-26    4856.0\n",
       "2021-03-27     884.0\n",
       "2021-03-28       0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02e86b4",
   "metadata": {},
   "source": [
    "### Create all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cf02a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def icas_egna_features(df):\n",
    "    features = {}\n",
    "\n",
    "    def add_weekday(features):\n",
    "        features['weekday'] = pd.Series(df.index.weekday, index=df.index)\n",
    "    \n",
    "    def add_day_of_month(features):\n",
    "        features['day_of_month'] = pd.Series(df.index.day, index=df.index)\n",
    "    \n",
    "    def add_holiday(features):\n",
    "        holidays = ['2021-01-01', '2021-01-06', '2021-04-02', '2021-04-04', '2021-04-05', '2020-05-21', '2020-05-31', '2020-06-06', '2020-06-20', '2020-10-31', '2020-12-25', '2020-12-26']\n",
    "        features['holiday'] = pd.Series(np.where(df.index.isin(holidays), 1, 0), index=df.index)\n",
    "    \n",
    "    def add_before_holiday(features):\n",
    "        features['before_holiday'] = pd.Series(0, index=df.index)\n",
    "        before_holidays = ['2021-01-01', '2021-04-02', '2020-06-06', '2020-12-24']\n",
    "        for holiday in before_holidays:\n",
    "            for i in range(1, 4):\n",
    "                features['before_holiday'][pd.to_datetime(holiday) - pd.DateOffset(i)] = i\n",
    "    \n",
    "    def add_payday(features, payday, pension=False):\n",
    "        if pension:\n",
    "            if 'pension' not in features:\n",
    "                features['pension'] = pd.Series(0, index=df.index) \n",
    "                series = features['pension']\n",
    "            else:\n",
    "                series = features['pension']\n",
    "                \n",
    "        if not pension:\n",
    "            features['payday'] = pd.Series(0, index=df.index)\n",
    "            series = features['payday']\n",
    "        \n",
    "        for i, day in enumerate(features['day_of_month']):\n",
    "            if day == payday:\n",
    "                if features['weekday'].iloc[i] in [5, 6] or features['holiday'].iloc[i]:\n",
    "                    paydays = i - 1 if features['weekday'].iloc[i-1] not in [5, 6] or features['holiday'].iloc[i -1] else i - 2\n",
    "                    series.iloc[paydays] = 1 \n",
    "                else:\n",
    "                    series.iloc[i] = 1\n",
    "    \n",
    "    add_weekday(features)\n",
    "    add_day_of_month(features)\n",
    "    add_holiday(features)\n",
    "    add_before_holiday(features)\n",
    "    add_payday(features, 25)\n",
    "    add_payday(features, 18, pension=True)\n",
    "    add_payday(features, 17, pension=True)\n",
    "\n",
    "    return features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0a26690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "features = icas_egna_features(df)\n",
    "for k, v in features.items():\n",
    "    print(type(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c54878",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbc22af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations, chain\n",
    "\n",
    "def feature_combinations(df, features):\n",
    "    features_combinations = list(chain.from_iterable([combinations(features, i) for i in range(1, len(features))]))\n",
    "\n",
    "    df_list = [df]\n",
    "    for f_comb in features_combinations:\n",
    "        ts = df.copy()\n",
    "        for feat in f_comb:\n",
    "            ts[feat] = features[feat]\n",
    "        df_list.append(ts)\n",
    "    \n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "646b8973",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = feature_combinations(df, features)\n",
    "df_list = df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58b11311",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "\n",
    "def scale_data(df_list):\n",
    "    scaled_df_list = []\n",
    "    for df in df_list:\n",
    "        min_max_scaler_x = MinMaxScaler(feature_range=(0, 1))\n",
    "        min_max_scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "        robust_scaler_x = RobustScaler()\n",
    "        robust_scaler_y = RobustScaler()\n",
    "\n",
    "        standard_scaler_x = StandardScaler()\n",
    "        standard_scaler_y = StandardScaler()\n",
    "        \n",
    "        scalers = [[min_max_scaler_x, min_max_scaler_y], [robust_scaler_x, robust_scaler_y], [standard_scaler_x, standard_scaler_y]]\n",
    "#     Unscaled doesn't work here!\n",
    "\n",
    "#         if len(df.columns) == 1:\n",
    "#             scaled_df_list.append({'X': df.iloc[:].to_numpy().reshape(-1, 1), \n",
    "#                                    'y': df.iloc[:].to_numpy().reshape(-1, 1), \n",
    "#                                    'scaler_x': None, \n",
    "#                                    'scaler_y': None,\n",
    "#                                    'features': df.columns})\n",
    "#         else:\n",
    "#             scaled_df_list.append({'X': df.iloc[:, :].to_numpy(), \n",
    "#                                    'y': df.iloc[:, 0].to_numpy().reshape(-1, 1), \n",
    "#                                    'scaler_x': None, \n",
    "#                                    'scaler_y': None,\n",
    "#                                    'features': df.columns})\n",
    "\n",
    "        for scaler in scalers:\n",
    "            if len(df.columns) == 1:\n",
    "                scaled_df_list.append({'X': scaler[0].fit_transform(df.iloc[:].to_numpy().reshape(-1, 1)), \n",
    "                                       'y': scaler[1].fit_transform(df.iloc[:].to_numpy().reshape(-1, 1)), \n",
    "                                       'scaler_x': scaler[0], \n",
    "                                       'scaler_y': scaler[1],\n",
    "                                       'features': df.columns})\n",
    "            else:\n",
    "                scaled_df_list.append({'X': scaler[0].fit_transform(df.iloc[:, :].to_numpy()), \n",
    "                                       'y': scaler[1].fit_transform(df.iloc[:, 0].to_numpy().reshape(-1, 1)), \n",
    "                                       'scaler_x': scaler[0], \n",
    "                                       'scaler_y': scaler[1],\n",
    "                                       'features': df.columns})\n",
    "    \n",
    "    return scaled_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e635db8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = scale_data(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a1b60d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_step(train_test, time_steps):\n",
    "    time_step_df = []\n",
    "    for time_step in time_steps:\n",
    "        for df in train_test:\n",
    "            new_df = {key: df[key] for key in ['scaler_y', 'scaler_x', 'features']}\n",
    "            \n",
    "            X_y = [[df['X'][i: (i + time_step)], df['y'][i + time_step]] for i in range(len(df['X']) - time_step)]\n",
    "            \n",
    "            new_df['X'], new_df['y'] = np.array([x for x, _ in X_y]), np.array([y for _, y in X_y])\n",
    "            new_df['time_steps'] = time_step\n",
    "\n",
    "            time_step_df.append(new_df)\n",
    "            \n",
    "    return time_step_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8debd0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = [7, 14]\n",
    "\n",
    "time_step_df = create_time_step(scaled_data, time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f5d1b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(scaled_data, test_size):\n",
    "    \n",
    "    return [{'X_train': df['X'][:len(df['X']) - test_size], \n",
    "             'y_train': df['y'][:len(df['X']) - test_size],\n",
    "             'X_test': df['X'][len(df['X']) - test_size:],\n",
    "             'y_test': df['y'][len(df['X']) - test_size:],\n",
    "             'scaler_x': df['scaler_x'],\n",
    "             'scaler_y': df['scaler_y'],\n",
    "             'time_steps': df['time_steps'],\n",
    "             'features': df['features']} \n",
    "             for df in scaled_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e07a069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378\n"
     ]
    }
   ],
   "source": [
    "train_test = split_train_test(time_step_df, 7)\n",
    "print(len(train_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e45cfe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(list_df):\n",
    "    for i, df in enumerate(list_df, 1):        \n",
    "        model = Sequential()\n",
    "        model.add(Bidirectional(\n",
    "                  LSTM(units=128, input_shape=(df['X_train'].shape[1], df['X_train'].shape[2])),\n",
    "                  merge_mode='sum'))\n",
    "        model.add(Dense(units=1))\n",
    "        model.compile(loss='mse', optimizer=Adam(learning_rate=0.001))\n",
    "        \n",
    "        print(f'Training {i}/{len(list_df)}'.center(50, '-'))\n",
    "                \n",
    "        history = model.fit(\n",
    "        df['X_train'], df['y_train'],\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_data=(df['X_test'], df['y_test']),\n",
    "        shuffle=False,\n",
    "        verbose=0\n",
    "        )\n",
    "\n",
    "        df['history'] = {'loss': history.history['loss'], 'val_loss': history.history['val_loss']}\n",
    "\n",
    "        predictions = model.predict(df['X_test'])\n",
    "        if df['scaler_y']:\n",
    "            df['predictions'] = df['scaler_y'].inverse_transform(predictions)\n",
    "            df['y_test'] = df['scaler_y'].inverse_transform(df['y_test'])\n",
    "        else:\n",
    "            df['predictions'] = predictions\n",
    "        \n",
    "        df['score'] = {'RMSE': np.sqrt(mean_squared_error(y_true=df['y_test'], y_pred=df['predictions'])),\n",
    "                       'MAE': mean_absolute_error(y_true=df['y_test'], y_pred=df['predictions']),\n",
    "                       'r2': r2_score(y_true=df['y_test'], y_pred=df['predictions'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39c068b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------Training 1/1-------------------\n"
     ]
    }
   ],
   "source": [
    "run_model([train_test[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8062153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_results(df_list):\n",
    "    with open('fitted_df_new.pkl', 'wb') as f:\n",
    "        pickle.dump(df_list, f)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29aa50c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_results():\n",
    "    with open('./fitted_data/trained_data.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1959659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_results(train_test)\n",
    "# fitted_dfs = open_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
