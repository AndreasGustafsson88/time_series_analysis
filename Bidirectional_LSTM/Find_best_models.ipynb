{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7093e0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Bidirectional, LSTM, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import pickle\n",
    "\n",
    "sns.set(style='darkgrid', palette='muted', font_scale=1.5, rc={'figure.figsize':(20,10)})\n",
    "\n",
    "RANDOM_SEED = 40\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c339844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "def open_param_results():\n",
    "    files = glob.glob('./hyper_param_test/*.pkl')\n",
    "    \n",
    "    all_models = []\n",
    "    for file in files:\n",
    "        with open(file, 'rb') as f:\n",
    "            [all_models.append(df) for df in pickle.load(f)] \n",
    "    return all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79738336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960\n"
     ]
    }
   ],
   "source": [
    "param_df = open_param_results()\n",
    "print(len(param_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "957fe297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top(df_list, num):\n",
    "    return sorted(df_list, key=lambda df: df['score']['r2'], reverse=True)[:num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c03229ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_dfs = get_top(param_df, 10)\n",
    "df = top_dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4123ee3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(list_df):\n",
    "    best_models = []\n",
    "    for i in range(100):\n",
    "        for j, df in enumerate(list_df, 1):\n",
    "            file_path = f'./fitted_models/{i}_{j}'\n",
    "            print(file_path)\n",
    "            \n",
    "            model = Sequential()\n",
    "            model.add(Bidirectional(\n",
    "                      LSTM(units=df['hyper_params']['units'], activation=df['hyper_params']['activation_function'], input_shape=(df['X_train'].shape[1], df['X_train'].shape[2])),\n",
    "                      merge_mode=df['hyper_params']['merge_mode']))\n",
    "            model.add(Dense(units=1))\n",
    "            model.compile(loss=df['hyper_params']['loss'], optimizer=df['hyper_params']['optimizer'])\n",
    "\n",
    "            print(f'Training {i + j}/{len(list_df) * 10}'.center(50, '-'))\n",
    "\n",
    "            history = model.fit(\n",
    "                df['X_train'], df['y_train'],\n",
    "                epochs=100,\n",
    "                batch_size=df['hyper_params']['batch_size'],\n",
    "                validation_data=(df['X_test'], df['scaler_y'].transform(df['y_test'])),\n",
    "                shuffle=False,\n",
    "                verbose=2\n",
    "            )\n",
    "\n",
    "            df['history'] = {'loss': history.history['loss'], 'val_loss': history.history['val_loss']}\n",
    "\n",
    "            predictions = model.predict(df['X_test'])\n",
    "\n",
    "            if df['scaler_y']:\n",
    "                df['predictions'] = df['scaler_y'].inverse_transform(predictions)\n",
    "            else:\n",
    "                df['predictions'] = predictions\n",
    "            \n",
    "            model.save(file_path)\n",
    "            \n",
    "            best_models.append({\n",
    "                'model': file_path,\n",
    "                **df.copy(), \n",
    "                **{'score': {\n",
    "                    'RMSE': np.sqrt(mean_squared_error(y_true=df['y_test'], y_pred=df['predictions'])),\n",
    "                    'MAE': mean_absolute_error(y_true=df['y_test'], y_pred=df['predictions']),\n",
    "                    'r2': r2_score(y_true=df['y_test'], y_pred=df['predictions'])}}\n",
    "            })\n",
    "            \n",
    "    return best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e7eac277",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./fitted_models/0_1\n",
      "------------------Training 1/20-------------------\n",
      "Epoch 1/25\n",
      "10/10 - 2s - loss: 0.9504 - val_loss: 0.7968\n",
      "Epoch 2/25\n",
      "10/10 - 1s - loss: 0.7490 - val_loss: 0.8277\n",
      "Epoch 3/25\n",
      "10/10 - 1s - loss: 0.9304 - val_loss: 0.8023\n",
      "Epoch 4/25\n",
      "10/10 - 1s - loss: 0.5026 - val_loss: 0.5943\n",
      "Epoch 5/25\n",
      "10/10 - 2s - loss: 0.5193 - val_loss: 0.5463\n",
      "Epoch 6/25\n",
      "10/10 - 2s - loss: 0.5051 - val_loss: 0.5507\n",
      "Epoch 7/25\n",
      "10/10 - 1s - loss: 0.4616 - val_loss: 0.5262\n",
      "Epoch 8/25\n",
      "10/10 - 1s - loss: 0.4499 - val_loss: 0.5017\n",
      "Epoch 9/25\n",
      "10/10 - 1s - loss: 0.4425 - val_loss: 0.4768\n",
      "Epoch 10/25\n",
      "10/10 - 1s - loss: 0.4262 - val_loss: 0.4649\n",
      "Epoch 11/25\n",
      "10/10 - 1s - loss: 0.4091 - val_loss: 0.4481\n",
      "Epoch 12/25\n",
      "10/10 - 1s - loss: 0.4023 - val_loss: 0.4381\n",
      "Epoch 13/25\n",
      "10/10 - 1s - loss: 0.4099 - val_loss: 0.4244\n",
      "Epoch 14/25\n",
      "10/10 - 1s - loss: 0.4006 - val_loss: 0.4169\n",
      "Epoch 15/25\n",
      "10/10 - 1s - loss: 0.3895 - val_loss: 0.4067\n",
      "Epoch 16/25\n",
      "10/10 - 1s - loss: 0.3900 - val_loss: 0.4028\n",
      "Epoch 17/25\n",
      "10/10 - 1s - loss: 0.3991 - val_loss: 0.3989\n",
      "Epoch 18/25\n",
      "10/10 - 1s - loss: 0.3990 - val_loss: 0.3853\n",
      "Epoch 19/25\n",
      "10/10 - 1s - loss: 0.3868 - val_loss: 0.3852\n",
      "Epoch 20/25\n",
      "10/10 - 1s - loss: 0.3797 - val_loss: 0.3783\n",
      "Epoch 21/25\n",
      "10/10 - 1s - loss: 0.3808 - val_loss: 0.3797\n",
      "Epoch 22/25\n",
      "10/10 - 1s - loss: 0.3894 - val_loss: 0.3850\n",
      "Epoch 23/25\n",
      "10/10 - 1s - loss: 0.4005 - val_loss: 0.3593\n",
      "Epoch 24/25\n",
      "10/10 - 1s - loss: 0.3895 - val_loss: 0.3493\n",
      "Epoch 25/25\n",
      "10/10 - 2s - loss: 0.3745 - val_loss: 0.3682\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000012063893940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "INFO:tensorflow:Assets written to: ./fitted_models/0_1\\assets\n",
      "./fitted_models/0_2\n",
      "------------------Training 2/20-------------------\n",
      "Epoch 1/25\n",
      "10/10 - 1s - loss: 1.0446 - val_loss: 1.3932\n",
      "Epoch 2/25\n",
      "10/10 - 1s - loss: 1.0102 - val_loss: 1.3251\n",
      "Epoch 3/25\n",
      "10/10 - 0s - loss: 0.9904 - val_loss: 1.2726\n",
      "Epoch 4/25\n",
      "10/10 - 1s - loss: 0.9790 - val_loss: 1.2355\n",
      "Epoch 5/25\n",
      "10/10 - 1s - loss: 0.9716 - val_loss: 1.2087\n",
      "Epoch 6/25\n",
      "10/10 - 1s - loss: 0.9659 - val_loss: 1.1884\n",
      "Epoch 7/25\n",
      "10/10 - 1s - loss: 0.9607 - val_loss: 1.1720\n",
      "Epoch 8/25\n",
      "10/10 - 1s - loss: 0.9558 - val_loss: 1.1581\n",
      "Epoch 9/25\n",
      "10/10 - 1s - loss: 0.9509 - val_loss: 1.1458\n",
      "Epoch 10/25\n",
      "10/10 - 1s - loss: 0.9459 - val_loss: 1.1346\n",
      "Epoch 11/25\n",
      "10/10 - 1s - loss: 0.9408 - val_loss: 1.1241\n",
      "Epoch 12/25\n",
      "10/10 - 1s - loss: 0.9356 - val_loss: 1.1140\n",
      "Epoch 13/25\n",
      "10/10 - 1s - loss: 0.9303 - val_loss: 1.1042\n",
      "Epoch 14/25\n",
      "10/10 - 1s - loss: 0.9248 - val_loss: 1.0947\n",
      "Epoch 15/25\n",
      "10/10 - 1s - loss: 0.9192 - val_loss: 1.0852\n",
      "Epoch 16/25\n",
      "10/10 - 1s - loss: 0.9134 - val_loss: 1.0759\n",
      "Epoch 17/25\n",
      "10/10 - 1s - loss: 0.9075 - val_loss: 1.0665\n",
      "Epoch 18/25\n",
      "10/10 - 1s - loss: 0.9014 - val_loss: 1.0572\n",
      "Epoch 19/25\n",
      "10/10 - 1s - loss: 0.8952 - val_loss: 1.0478\n",
      "Epoch 20/25\n",
      "10/10 - 1s - loss: 0.8889 - val_loss: 1.0384\n",
      "Epoch 21/25\n",
      "10/10 - 1s - loss: 0.8824 - val_loss: 1.0289\n",
      "Epoch 22/25\n",
      "10/10 - 1s - loss: 0.8758 - val_loss: 1.0194\n",
      "Epoch 23/25\n",
      "10/10 - 1s - loss: 0.8691 - val_loss: 1.0098\n",
      "Epoch 24/25\n",
      "10/10 - 1s - loss: 0.8623 - val_loss: 1.0001\n",
      "Epoch 25/25\n",
      "10/10 - 1s - loss: 0.8554 - val_loss: 0.9904\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001205B830A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "INFO:tensorflow:Assets written to: ./fitted_models/0_2\\assets\n",
      "./fitted_models/1_1\n",
      "------------------Training 2/20-------------------\n",
      "Epoch 1/25\n",
      "10/10 - 2s - loss: 1.2468 - val_loss: 1.2000\n",
      "Epoch 2/25\n",
      "10/10 - 2s - loss: 1.2629 - val_loss: 1.1771\n",
      "Epoch 3/25\n",
      "10/10 - 1s - loss: 0.5772 - val_loss: 0.6430\n",
      "Epoch 4/25\n",
      "10/10 - 1s - loss: 0.6646 - val_loss: 0.6819\n",
      "Epoch 5/25\n",
      "10/10 - 1s - loss: 0.4776 - val_loss: 0.5701\n",
      "Epoch 6/25\n",
      "10/10 - 1s - loss: 0.4933 - val_loss: 0.5623\n",
      "Epoch 7/25\n",
      "10/10 - 1s - loss: 0.4664 - val_loss: 0.5493\n",
      "Epoch 8/25\n",
      "10/10 - 1s - loss: 0.4435 - val_loss: 0.5290\n",
      "Epoch 9/25\n",
      "10/10 - 1s - loss: 0.4317 - val_loss: 0.5042\n",
      "Epoch 10/25\n",
      "10/10 - 1s - loss: 0.4240 - val_loss: 0.4862\n",
      "Epoch 11/25\n",
      "10/10 - 1s - loss: 0.4114 - val_loss: 0.4807\n",
      "Epoch 12/25\n",
      "10/10 - 1s - loss: 0.4037 - val_loss: 0.4446\n",
      "Epoch 13/25\n",
      "10/10 - 1s - loss: 0.4055 - val_loss: 0.4350\n",
      "Epoch 14/25\n",
      "10/10 - 1s - loss: 0.3948 - val_loss: 0.4349\n",
      "Epoch 15/25\n",
      "10/10 - 1s - loss: 0.3880 - val_loss: 0.4142\n",
      "Epoch 16/25\n",
      "10/10 - 1s - loss: 0.3964 - val_loss: 0.4142\n",
      "Epoch 17/25\n",
      "10/10 - 1s - loss: 0.3858 - val_loss: 0.4078\n",
      "Epoch 18/25\n",
      "10/10 - 1s - loss: 0.3780 - val_loss: 0.3907\n",
      "Epoch 19/25\n",
      "10/10 - 1s - loss: 0.3822 - val_loss: 0.3854\n",
      "Epoch 20/25\n",
      "10/10 - 1s - loss: 0.3797 - val_loss: 0.3778\n",
      "Epoch 21/25\n",
      "10/10 - 1s - loss: 0.3768 - val_loss: 0.3711\n",
      "Epoch 22/25\n",
      "10/10 - 1s - loss: 0.3720 - val_loss: 0.3698\n",
      "Epoch 23/25\n",
      "10/10 - 1s - loss: 0.3717 - val_loss: 0.3654\n",
      "Epoch 24/25\n",
      "10/10 - 1s - loss: 0.3792 - val_loss: 0.3568\n",
      "Epoch 25/25\n",
      "10/10 - 1s - loss: 0.3710 - val_loss: 0.3437\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001206077E820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "INFO:tensorflow:Assets written to: ./fitted_models/1_1\\assets\n",
      "./fitted_models/1_2\n",
      "------------------Training 3/20-------------------\n",
      "Epoch 1/25\n",
      "10/10 - 1s - loss: 1.0389 - val_loss: 1.3784\n",
      "Epoch 2/25\n",
      "10/10 - 0s - loss: 1.0064 - val_loss: 1.3146\n",
      "Epoch 3/25\n",
      "10/10 - 0s - loss: 0.9879 - val_loss: 1.2644\n",
      "Epoch 4/25\n",
      "10/10 - 0s - loss: 0.9770 - val_loss: 1.2285\n",
      "Epoch 5/25\n",
      "10/10 - 0s - loss: 0.9697 - val_loss: 1.2023\n",
      "Epoch 6/25\n",
      "10/10 - 0s - loss: 0.9640 - val_loss: 1.1823\n",
      "Epoch 7/25\n",
      "10/10 - 0s - loss: 0.9587 - val_loss: 1.1660\n",
      "Epoch 8/25\n",
      "10/10 - 0s - loss: 0.9537 - val_loss: 1.1521\n",
      "Epoch 9/25\n",
      "10/10 - 1s - loss: 0.9486 - val_loss: 1.1397\n",
      "Epoch 10/25\n",
      "10/10 - 0s - loss: 0.9435 - val_loss: 1.1284\n",
      "Epoch 11/25\n",
      "10/10 - 0s - loss: 0.9383 - val_loss: 1.1177\n",
      "Epoch 12/25\n",
      "10/10 - 0s - loss: 0.9329 - val_loss: 1.1075\n",
      "Epoch 13/25\n",
      "10/10 - 0s - loss: 0.9275 - val_loss: 1.0976\n",
      "Epoch 14/25\n",
      "10/10 - 0s - loss: 0.9218 - val_loss: 1.0879\n",
      "Epoch 15/25\n",
      "10/10 - 0s - loss: 0.9161 - val_loss: 1.0784\n",
      "Epoch 16/25\n",
      "10/10 - 0s - loss: 0.9102 - val_loss: 1.0689\n",
      "Epoch 17/25\n",
      "10/10 - 0s - loss: 0.9042 - val_loss: 1.0594\n",
      "Epoch 18/25\n",
      "10/10 - 0s - loss: 0.8980 - val_loss: 1.0500\n",
      "Epoch 19/25\n",
      "10/10 - 0s - loss: 0.8917 - val_loss: 1.0406\n",
      "Epoch 20/25\n",
      "10/10 - 0s - loss: 0.8853 - val_loss: 1.0311\n",
      "Epoch 21/25\n",
      "10/10 - 0s - loss: 0.8788 - val_loss: 1.0216\n",
      "Epoch 22/25\n",
      "10/10 - 1s - loss: 0.8722 - val_loss: 1.0121\n",
      "Epoch 23/25\n",
      "10/10 - 1s - loss: 0.8655 - val_loss: 1.0025\n",
      "Epoch 24/25\n",
      "10/10 - 0s - loss: 0.8587 - val_loss: 0.9929\n",
      "Epoch 25/25\n",
      "10/10 - 0s - loss: 0.8518 - val_loss: 0.9832\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001205C500EE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "INFO:tensorflow:Assets written to: ./fitted_models/1_2\\assets\n"
     ]
    }
   ],
   "source": [
    "best_models = run_models(top_dfs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ad03ec0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_results(df_list, name):\n",
    "    with open(f'./fitted_models/{name}.pkl', 'wb') as f:\n",
    "        pickle.dump(df_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d01cad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(best_models, 'fitted_models')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
